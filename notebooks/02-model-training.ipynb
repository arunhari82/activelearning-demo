{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd5585-23bd-4a12-b71a-1c8d3cc310e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "%pip install -q -U pip\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d01b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters\n",
    "scratch = \"../scratch/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d696475-c96e-4081-b892-fe9083e74b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, random, pathlib, warnings, itertools, math, json\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "from shutil import rmtree\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cae101-768b-4cda-bbcf-498bfe44d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81c07f-97b7-4a8b-ae5e-cb7dc199b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths for data\n",
    "dataset = scratch + \"Vegetable Images\"\n",
    "\n",
    "train_folder = os.path.join(dataset, \"train\")\n",
    "test_folder = os.path.join(dataset, \"validation\")\n",
    "validation_folder = os.path.join(dataset, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea0ca7-e7da-428e-bb15-4f0c0a6f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "inception = InceptionV3(\n",
    "    input_shape=IMAGE_SIZE + [3], weights=\"imagenet\", include_top=False\n",
    ")\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "prediction = Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=prediction)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    rescale=1.0 / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_folder, target_size=(224, 224), batch_size=64, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_folder, target_size=(224, 224), batch_size=64, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "class_map = training_set.class_indices\n",
    "print(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff593ae4-9b92-4498-b3e8-4885c257b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = \"_inceptionV3_epoch5\"\n",
    "path_to_model = scratch + \"model\" + model_metadata + \".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path_to_model):\n",
    "    r = model.fit(\n",
    "        training_set,\n",
    "        validation_data=test_set,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=len(training_set),\n",
    "        validation_steps=len(test_set),\n",
    "    )\n",
    "    \n",
    "    model.save(path_to_model)\n",
    "\n",
    "else:\n",
    "    print(\"Model: already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61e391-33af-451b-bb1a-f4660e3e70f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "print(\"Model: Loading...\")\n",
    "model = load_model(path_to_model)\n",
    "print(\"Model: Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = {v: k for k, v in class_map.items()}\n",
    "print(json.dumps(category, indent=4))\n",
    "\n",
    "\n",
    "def predict_image(filename, model):\n",
    "    img_ = image.load_img(filename, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img_)\n",
    "    img_processed = np.expand_dims(img_array, axis=0)\n",
    "    img_processed /= 255.0\n",
    "\n",
    "    prediction = model.predict(img_processed)\n",
    "    index = np.argmax(prediction)\n",
    "\n",
    "    plt.title(\"Prediction - {}\".format(category[index]))\n",
    "    plt.imshow(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7202baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(os.path.join(validation_folder, \"Cauliflower/1064.jpg\"), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664eaa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(os.path.join(validation_folder, \"Bitter_Gourd/1202.jpg\"), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955567f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(os.path.join(validation_folder, \"Papaya/1266.jpg\"), model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
